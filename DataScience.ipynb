{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import uuid\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'acc_x_dashboard', 'acc_y_dashboard', 'acc_z_dashboard',\n",
      "       'acc_x_above_suspension', 'acc_y_above_suspension',\n",
      "       'acc_z_above_suspension', 'acc_x_below_suspension',\n",
      "       'acc_y_below_suspension', 'acc_z_below_suspension', 'gyro_x_dashboard',\n",
      "       'gyro_y_dashboard', 'gyro_z_dashboard', 'gyro_x_above_suspension',\n",
      "       'gyro_y_above_suspension', 'gyro_z_above_suspension',\n",
      "       'gyro_x_below_suspension', 'gyro_y_below_suspension',\n",
      "       'gyro_z_below_suspension', 'mag_x_dashboard', 'mag_y_dashboard',\n",
      "       'mag_z_dashboard', 'mag_x_above_suspension', 'mag_y_above_suspension',\n",
      "       'mag_z_above_suspension', 'temp_t_dashboard', 'temp_t_above_suspension',\n",
      "       'temp_t_below_suspension', 'timestamp_gps', 'latitude', 'longitude',\n",
      "       'speed', 'procedure', 'dataset', 'Road_Surface_Type_Labels',\n",
      "       'Road_Surface_Condition', 'Road_Roughness_Condition_Left',\n",
      "       'Road_Roughness_Condition_Right', 'Speed_Bump_Types', 'unique_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_list01 = []\n",
    "df_list02 = []\n",
    "final_df_list01 = []\n",
    "final_df_list02 = []\n",
    "for root, directories, files in os.walk('./DataSet'):\n",
    "    for file in files:\n",
    "        if file.endswith('right.csv'):\n",
    "            df = pd.read_csv(os.path.join(root, file))\n",
    "            df['procedure'] = 'network01'\n",
    "            df_list01.append(df)\n",
    "        elif file.endswith('left.csv'):\n",
    "            df = pd.read_csv(os.path.join(root, file))\n",
    "            df['procedure'] = 'network02'\n",
    "            df_list02.append(df)\n",
    "        elif file.endswith('labels.csv'):\n",
    "            df = pd.read_csv(os.path.join(root, file))\n",
    "            df['dataset'] = root.rsplit('/', 1)[-1]\n",
    "            df_list01.append(df)\n",
    "            df_list02.append(df)\n",
    "    if df_list01:\n",
    "         combined_df01 = pd.concat(df_list01, axis=1)\n",
    "         final_df_list01.append(combined_df01)\n",
    "         df_list01.clear()\n",
    "    else:\n",
    "         combined_df = pd.DataFrame()\n",
    "\n",
    "    if df_list02:\n",
    "         combined_df02 = pd.concat(df_list02, axis=1)\n",
    "         final_df_list02.append(combined_df02)\n",
    "         df_list02.clear()\n",
    "    else:\n",
    "         combined_df = pd.DataFrame()\n",
    "\n",
    "final_df01 = pd.concat(final_df_list01, axis=0)\n",
    "final_df02 = pd.concat(final_df_list02, axis=0)\n",
    "\n",
    "final_df = pd.concat([final_df01, final_df02], axis=0)\n",
    "\n",
    "new_column_names = {\n",
    "    'temp_dashboard': 'temp_t_dashboard',\n",
    "    'temp_above_suspension': 'temp_t_above_suspension',\n",
    "    'temp_below_suspension': 'temp_t_below_suspension'\n",
    "}\n",
    "final_df.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "\n",
    "Road_Surface_Condition = final_df[['paved_road', 'unpaved_road']]\n",
    "Road_Surface_Type_Labels = final_df[['dirt_road', 'cobblestone_road', 'asphalt_road']]\n",
    "Road_Roughness_Condition_Left = final_df[['good_road_left', 'regular_road_left','bad_road_left']]\n",
    "Road_Roughness_Condition_Right = final_df[['good_road_right', 'regular_road_right','bad_road_right']]\n",
    "Speed_Bump_Types= final_df[['no_speed_bump', 'speed_bump_asphalt','speed_bump_cobblestone']]\n",
    "final_df['Road_Surface_Type_Labels'] = pd.Series(Road_Surface_Type_Labels.columns[np.where(Road_Surface_Type_Labels !=0)[1]])\n",
    "final_df['Road_Surface_Condition'] = pd.Series(Road_Surface_Condition.columns[np.where(Road_Surface_Condition !=0)[1]])\n",
    "final_df['Road_Roughness_Condition_Left'] = pd.Series(Road_Roughness_Condition_Left.columns[np.where(Road_Roughness_Condition_Left !=0)[1]])\n",
    "final_df['Road_Roughness_Condition_Right'] = pd.Series(Road_Roughness_Condition_Right.columns[np.where(Road_Roughness_Condition_Right !=0)[1]])\n",
    "final_df['Speed_Bump_Types'] = pd.Series(Speed_Bump_Types.columns[np.where(Speed_Bump_Types !=0)[1]])\n",
    "final_df = final_df.drop(columns=['paved_road', 'unpaved_road','dirt_road', 'cobblestone_road', 'asphalt_road','good_road_left', 'regular_road_left','bad_road_left',                                      'good_road_right', 'regular_road_right','bad_road_right', 'no_speed_bump', 'speed_bump_asphalt','speed_bump_cobblestone'])\n",
    "final_df['unique_id'] = [str(uuid.uuid4())[:8] for _ in range(len(final_df))]\n",
    "print(final_df.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'acc_x_dashboard', 'acc_y_dashboard', 'acc_z_dashboard',\n",
      "       'acc_x_above_suspension', 'acc_y_above_suspension',\n",
      "       'acc_z_above_suspension', 'acc_x_below_suspension',\n",
      "       'acc_y_below_suspension', 'acc_z_below_suspension', 'gyro_x_dashboard',\n",
      "       'gyro_y_dashboard', 'gyro_z_dashboard', 'gyro_x_above_suspension',\n",
      "       'gyro_y_above_suspension', 'gyro_z_above_suspension',\n",
      "       'gyro_x_below_suspension', 'gyro_y_below_suspension',\n",
      "       'gyro_z_below_suspension', 'mag_x_dashboard', 'mag_y_dashboard',\n",
      "       'mag_z_dashboard', 'mag_x_above_suspension', 'mag_y_above_suspension',\n",
      "       'mag_z_above_suspension', 'temp_t_dashboard', 'temp_t_above_suspension',\n",
      "       'temp_t_below_suspension', 'timestamp_gps', 'latitude', 'longitude',\n",
      "       'speed', 'procedure', 'Road_Surface_Type_Labels',\n",
      "       'Road_Surface_Condition', 'Road_Roughness_Condition_Left',\n",
      "       'Road_Roughness_Condition_Right', 'Speed_Bump_Types', 'unique_id',\n",
      "       'Unnamed: 0', 'Vehicle', 'Driver', 'Scenario', 'Distance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_collection_contexts = pd.read_csv('./DataSet/data_collection_contexts.csv')\n",
    "PVS_Dataset_complete  = final_df.set_index('dataset').join(data_collection_contexts.set_index('DataSet'))\n",
    "shuffled_df = PVS_Dataset_complete.sample(frac=1, random_state=42)\n",
    "PVS_Dataset = shuffled_df[:10000]\n",
    "print(PVS_Dataset.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['measure', 'sensor', 'property', 'feature', 'platform', 'timestamp_gps',\n",
      "       'vehicle', 'procedure', 'driver', 'scenario', 'latitude', 'longitude',\n",
      "       'Distance', 'datetime', 'unique_id', 'Road_Surface_Type_Labels',\n",
      "       'Road_Surface_Condition', 'Road_Roughness_Condition_Left',\n",
      "       'Road_Roughness_Condition_Right', 'Speed_Bump_Types'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "property = ['acc_x_dashboard', 'acc_y_dashboard', 'acc_z_dashboard',\n",
    "       'acc_x_above_suspension', 'acc_y_above_suspension',\n",
    "       'acc_z_above_suspension', 'acc_x_below_suspension',\n",
    "       'acc_y_below_suspension', 'acc_z_below_suspension', 'gyro_x_dashboard',\n",
    "       'gyro_y_dashboard', 'gyro_z_dashboard', 'gyro_x_above_suspension',\n",
    "       'gyro_y_above_suspension', 'gyro_z_above_suspension',\n",
    "       'gyro_x_below_suspension', 'gyro_y_below_suspension',\n",
    "       'gyro_z_below_suspension', 'mag_x_dashboard', 'mag_y_dashboard',\n",
    "       'mag_z_dashboard', 'mag_x_above_suspension', 'mag_y_above_suspension',\n",
    "       'mag_z_above_suspension', 'temp_t_dashboard', 'temp_t_above_suspension',\n",
    "       'temp_t_below_suspension']\n",
    "\n",
    "labels = []\n",
    "table_list = []\n",
    "for column_name in PVS_Dataset.columns:\n",
    "    if column_name in property:\n",
    "        column_values = PVS_Dataset[column_name].values.tolist()\n",
    "\n",
    "        new_df = pd.DataFrame({'measure': column_values})\n",
    "\n",
    "        column_name_split = column_name.split('_')\n",
    "        if len(column_name_split) == 3 :\n",
    "            new_df['sensor'] = column_name_split[0]\n",
    "            new_df['property'] = '_'.join(column_name_split[:2])\n",
    "            new_df['feature'] = column_name_split[-1]\n",
    "            if column_name_split[0] == \"mag\":\n",
    "                new_df['platform'] = \"AK8963\"\n",
    "            else:\n",
    "                new_df['platform'] = 'MPU-6500'\n",
    "        elif len(column_name_split) == 4 :\n",
    "            new_df['sensor'] = column_name_split[0]\n",
    "            new_df['property'] = '_'.join(column_name_split[:2])\n",
    "            new_df['feature'] = '_'.join(column_name_split[2:])\n",
    "            if column_name_split[0] == \"mag\":\n",
    "                new_df['platform'] = \"AK8963\"\n",
    "            else:\n",
    "                new_df['platform'] = 'MPU-6500'\n",
    "\n",
    "        new_df['timestamp_gps'] = PVS_Dataset['timestamp_gps'].to_numpy()\n",
    "        new_df['vehicle'] = PVS_Dataset['Vehicle'].to_numpy()\n",
    "        new_df['procedure'] = PVS_Dataset['procedure'].to_numpy()\n",
    "        new_df['driver'] = PVS_Dataset['Driver'].to_numpy()\n",
    "        new_df['scenario'] = PVS_Dataset['Scenario'].to_numpy()\n",
    "        new_df['latitude'] = PVS_Dataset['latitude'].to_numpy()\n",
    "        new_df['longitude'] = PVS_Dataset['longitude'].to_numpy()\n",
    "        new_df['Distance'] = PVS_Dataset['Scenario'].to_numpy()\n",
    "        new_df['datetime'] = PVS_Dataset['timestamp'].to_numpy()\n",
    "        new_df['unique_id'] = PVS_Dataset['unique_id'].to_numpy()\n",
    "        new_df['Road_Surface_Type_Labels'] = PVS_Dataset['Road_Surface_Type_Labels'].to_numpy()\n",
    "        new_df['Road_Surface_Condition'] = PVS_Dataset['Road_Surface_Condition'].to_numpy()\n",
    "        new_df['Road_Roughness_Condition_Left'] = PVS_Dataset['Road_Roughness_Condition_Left'].to_numpy()\n",
    "        new_df['Road_Roughness_Condition_Right'] = PVS_Dataset['Road_Roughness_Condition_Right'].to_numpy()\n",
    "        new_df['Speed_Bump_Types'] = PVS_Dataset['Speed_Bump_Types'].to_numpy()\n",
    "        table_list.append(new_df)\n",
    "\n",
    "features_table = pd.concat(table_list, axis=0)\n",
    "features_table.to_csv('./outputs/rowData/features.csv')\n",
    "print(features_table.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-07-09 12:28:21,072 | Parallelization is not supported for darwin when running as a library. If you need to speed up your data integration pipeline, please run through the command line.\n",
      "INFO | 2023-07-09 12:28:21,447 | 60 mapping rules retrieved.\n",
      "INFO | 2023-07-09 12:28:21,470 | Mapping partition with 60 groups generated.\n",
      "INFO | 2023-07-09 12:28:21,471 | Maximum number of rules within mapping group: 1.\n",
      "INFO | 2023-07-09 12:28:21,471 | Mappings processed in 0.397 seconds.\n",
      "INFO | 2023-07-09 12:28:49,115 | Number of triples generated in total: 1655440.\n"
     ]
    }
   ],
   "source": [
    "import morph_kgc\n",
    "graph = morph_kgc.materialize(\"./mapping/config.ini\")\n",
    "graph.serialize(destination=\"./outputs/triples/result.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rdflib import Graph, store\n",
    "\n",
    "g = Graph(store='neo4j-cypher')\n",
    "theconfig = {'uri': \"bolt://localhost:7687\", 'database': 'neo4j', 'auth': {'user': \"neo4j\", 'pwd': \"28071382\"}}\n",
    "\n",
    "g.open(theconfig, create = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g.store.startBatchedWrite()\n",
    "g.parse(\"./outputs/triples/result.txt\", format=\"ttl\")\n",
    "g.store.endBatchedWrite()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
